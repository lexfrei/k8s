---
# Node preparation role - Default package lists
# These variables can be overridden in group_vars or host_vars

# Kubernetes dependencies
# Required for K3s storage and networking functionality
# TODO: After TrueNAS migration, nfs-common only needed on RPi nodes (if at all)
# TODO: cpufrequtils only needed on RPi nodes (Xeon uses intel_pstate)
node_prep_k8s_packages:
  - nfs-common          # NFS client for NFS-based storage (documented in Error 14)
  - multipath-tools     # Device mapper multipath support for storage
  - open-iscsi          # iSCSI initiator (required by Longhorn distributed storage)

# Quality of life tools
# Useful utilities for cluster management and troubleshooting
node_prep_qol_packages:
  - vim                 # Text editor for configuration
  - etcd-client         # etcdctl command-line tool for K3s embedded etcd

# System utilities
# Hardware and system monitoring tools
node_prep_system_packages:
  - cpufrequtils        # CPU frequency scaling utilities (see Error 9 for governor config)
  - watchdog            # Hardware watchdog daemon (configured in Error 9, 13)
  - smartmontools       # SMART disk health monitoring
  - systemd-timesyncd   # Time synchronization daemon

# Combined package list (all categories)
# This is what gets installed by apt-packages.yml
node_prep_apt_packages: "{{ node_prep_k8s_packages + node_prep_qol_packages + node_prep_system_packages }}"

# APT configuration
node_prep_apt_cache_valid_time: 3600  # Cache validity in seconds (1 hour)
node_prep_apt_retries: 3              # Number of retry attempts
node_prep_apt_retry_delay: 10         # Delay between retries in seconds

# Sysctl - Kernel panic settings
# Converted from Argo Workflows manifests/argo-workflows/workflow-template-new-node-setup.yaml
node_prep_kernel_panic: 10                    # Reboot after 10 seconds on kernel panic
node_prep_kernel_panic_on_oops: 1            # Panic on kernel oops
node_prep_vm_panic_on_oom: 0                 # Do not panic on OOM
node_prep_kernel_hung_task_panic: 0          # Do not panic on hung tasks

# Sysctl - Filesystem optimization
# Converted from Argo Workflows
node_prep_vm_swappiness: 1                   # Minimal swap usage
node_prep_vm_dirty_background_ratio: 5       # Start writeback at 5% dirty pages
node_prep_vm_dirty_ratio: 10                 # Force writeback at 10% dirty pages
node_prep_vm_dirty_expire_centisecs: 1500    # 15 seconds
node_prep_vm_dirty_writeback_centisecs: 500  # 5 seconds
node_prep_fs_file_max: 2097152               # Maximum open files
node_prep_fs_inotify_max_user_watches: 524288  # inotify watches (K8s needs this)
node_prep_fs_inotify_max_user_instances: 512   # inotify instances
node_prep_fs_inotify_max_queued_events: 65536  # inotify queue size
node_prep_fs_aio_max_nr: 1048576             # Async I/O limit
node_prep_vm_overcommit_memory: 0            # Heuristic overcommit

# DNS configuration (systemd-resolved)
# Converted from Argo Workflows
node_prep_dns_primary: "172.16.0.1"          # Primary DNS server
node_prep_dns_fallback: "8.8.8.8 1.1.1.1"   # Fallback DNS servers

# DNS timeouts and caching
node_prep_dns_stub_listener_extra: "127.0.0.54"  # Additional DNS stub listener
node_prep_dns_cache: "yes"                       # Enable DNS caching
node_prep_dns_cache_from_localhost: "no"         # Don't cache localhost queries
node_prep_dns_over_tls: "no"                     # Disable DNS over TLS
node_prep_dns_multicast: "no"                    # Disable mDNS
node_prep_dns_llmnr: "no"                        # Disable LLMNR
node_prep_dns_read_etc_hosts: "yes"              # Use /etc/hosts
node_prep_dns_resolve_unicast_single_label: "no"  # Don't resolve single-label names
node_prep_dns_stale_retention_sec: 3600          # Keep stale entries for 1 hour

# Watchdog configuration
# Note: watchdog package is installed via node_prep_system_packages
# Three-level protection:
#   1. Ping failure -> repair script tries macb module reload
#   2. If repair fails -> software reboot via watchdog daemon
#   3. If system hangs (no heartbeat) -> hardware reboot via bcm2835_wdt
# See Error 15 in CLAUDE.md for context (RPi5 network death without link down)
node_prep_watchdog_device: "/dev/watchdog"
node_prep_watchdog_timeout: 60               # Hardware timeout: 60s (bcm2835_wdt failsafe)
node_prep_watchdog_interval: 15              # Heartbeat and ping check every 15 seconds
node_prep_watchdog_realtime: "yes"
node_prep_watchdog_priority: 1
node_prep_watchdog_ping_target: "172.16.0.1" # Gateway to ping
node_prep_watchdog_retry_timeout: 60         # Trigger repair after 60 seconds of ping failure
node_prep_watchdog_repair_binary: "/usr/local/bin/watchdog-network-repair.sh"
node_prep_watchdog_repair_timeout: 30        # Seconds for repair script to complete

# CPU frequency governor
# Set to "performance" to avoid RCU stalls from frequency scaling
# on Raspberry Pi 5 with RP1 southbridge (kernel 6.17+)
# See: https://github.com/lexfrei/k8s/issues/526
node_prep_cpu_governor: "performance"

# Timezone configuration
# UTC is standard for servers - ensures consistent log timestamps across cluster
node_prep_timezone: "Etc/UTC"

# Journald configuration
node_prep_journald_runtime_max_use: "100M"   # Max volatile log size in tmpfs

# ZFS configuration (storage nodes only)
node_prep_zfs_arc_max: 8589934592            # 8 GB ARC limit
node_prep_zfs_arc_max_human: "8 GB"          # Human-readable for comments

# System upgrade configuration
node_prep_system_upgrade_enabled: false      # Upgrade disabled by default (use playbook)
node_prep_reboot_if_required: true           # Auto-reboot enabled by default

# Sysctl - Network optimization
# TCP buffer sizes for high throughput (NFS, container images, backups)
node_prep_net_core_rmem_max: 16777216          # Maximum receive buffer (16MB)
node_prep_net_core_wmem_max: 16777216          # Maximum send buffer (16MB)
node_prep_net_core_rmem_default: 262144        # Default receive buffer (256KB)
node_prep_net_core_wmem_default: 262144        # Default send buffer (256KB)
node_prep_net_ipv4_tcp_rmem: "4096 131072 16777216"  # TCP receive buffer (min, default, max)
node_prep_net_ipv4_tcp_wmem: "4096 131072 16777216"  # TCP send buffer (min, default, max)

# Connection queue limits (prevents drops under load)
node_prep_net_core_somaxconn: 32768            # Listen backlog queue
node_prep_net_ipv4_tcp_max_syn_backlog: 8192   # SYN queue for new connections
node_prep_net_core_netdev_max_backlog: 16384   # Packet queue before processing
node_prep_net_core_netdev_budget: 600          # NAPI poll budget
node_prep_net_core_netdev_budget_usecs: 8000   # NAPI poll time budget

# TCP performance tuning
node_prep_net_ipv4_tcp_fastopen: 3             # TFO for client and server
node_prep_net_ipv4_tcp_tw_reuse: 1             # Reuse TIME_WAIT sockets
node_prep_net_ipv4_tcp_fin_timeout: 15         # FIN_WAIT2 timeout (seconds)
node_prep_net_ipv4_tcp_keepalive_time: 600     # Keepalive start (seconds)
node_prep_net_ipv4_tcp_keepalive_probes: 5     # Keepalive probe count
node_prep_net_ipv4_tcp_keepalive_intvl: 15     # Keepalive probe interval
node_prep_net_ipv4_ip_local_port_range: "1024 65535"  # Ephemeral port range

# Congestion control (complements Cilium BBR for host traffic)
node_prep_net_core_default_qdisc: "fq"         # Fair Queue qdisc
node_prep_net_ipv4_tcp_congestion_control: "bbr"  # BBR congestion control

# Network security hardening
node_prep_net_ipv4_tcp_syncookies: 1           # SYN flood protection
node_prep_net_ipv4_conf_all_rp_filter: 1       # Reverse path filtering
node_prep_net_ipv4_conf_default_rp_filter: 1
node_prep_net_ipv4_icmp_echo_ignore_broadcasts: 1  # Ignore broadcast pings
node_prep_net_ipv4_conf_all_accept_redirects: 0    # Ignore ICMP redirects
node_prep_net_ipv4_conf_default_accept_redirects: 0
node_prep_net_ipv4_conf_all_send_redirects: 0      # Don't send ICMP redirects
node_prep_net_ipv4_conf_default_send_redirects: 0

# IP forwarding (required for Kubernetes networking)
node_prep_net_ipv4_ip_forward: 1
node_prep_net_ipv4_conf_all_forwarding: 1
